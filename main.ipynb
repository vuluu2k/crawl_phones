{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://hatocase.com/tu-thiet-ke-op-lung-dien-thoai/\")\n",
    "\n",
    "element = driver.find_element(By.CSS_SELECTOR, \".row.row-collapse.row-full-width\")\n",
    "elements = element.find_elements(By.CLASS_NAME, \"col-inner\")\n",
    "wait = WebDriverWait(driver, 30)\n",
    "file = open(\"data.csv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for element in elements:\n",
    "    group = element.text\n",
    "    element.click()\n",
    "    wait.until(lambda x: x.find_element(By.CLASS_NAME, \"mfp-wrap\"))\n",
    "    wrapper = driver.find_element(By.CLASS_NAME, \"mfp-wrap\")\n",
    "    close_el = wrapper.find_element(By.CLASS_NAME, \"mfp-close\")\n",
    "    content = wrapper.find_element(By.CLASS_NAME, \"mfp-content\")\n",
    " \n",
    "    lightbox = content.find_element(By.CLASS_NAME, \"lightbox-by-id\")\n",
    "    accordion_list = lightbox.find_elements(By.CLASS_NAME, \"accordion\")\n",
    "    if len(accordion_list) > 0:\n",
    "        accordion_item_list = accordion_list[0].find_elements(By.CLASS_NAME, \"accordion-item\")\n",
    "        for accordion_item in accordion_item_list:\n",
    "            accordion_item.click()\n",
    "            accordion_title = accordion_item.find_element(By.CSS_SELECTOR, \".accordion-title span\").text\n",
    "            row = accordion_item.find_element(By.CLASS_NAME, \"row\")\n",
    "            phones = row.find_elements(By.CLASS_NAME, \"col\")\n",
    "            for phone in phones:\n",
    "                a_tag = phone.find_element(By.TAG_NAME, \"a\")\n",
    "                wait.until(EC.presence_of_element_located((By.TAG_NAME, \"span\")))\n",
    "                href = a_tag.get_attribute(\"href\")\n",
    "                text = a_tag.find_element(By.TAG_NAME, \"span\").text\n",
    "                \n",
    "                if \"#dongdienthoaikhac\" not in href:\n",
    "                    file.write(group + \",\" + accordion_title + \",\" + text + \",\" + href + \"\\n\")\n",
    "    else:\n",
    "        row = content.find_element(By.CLASS_NAME, \"row\")\n",
    "        phones = row.find_elements(By.CLASS_NAME, \"col\")\n",
    "        for phone in phones:\n",
    "            text = phone.find_element(By.TAG_NAME, \"span\").text\n",
    "            href = phone.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            if \"#dongdienthoaikhac\" not in href:\n",
    "                file.write(group + \",None,\" + text + \",\" + href + \"\\n\")\n",
    "    close_el.click()\n",
    "\n",
    "\n",
    "file.close()\n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup    \n",
    "import re\n",
    "import json    \n",
    "file_write = open(\"data_full.csv\", \"w\", encoding=\"utf-8\")\n",
    "file = open(\"data.csv\", \"r\", encoding=\"utf-8\")\n",
    "file_write.write(\"Group,SubGroup,Phone,Link,Image,Background,Upload,Border\\n\")\n",
    "for line in file:\n",
    "    group, sub_group, text, href = line.split(\",\")\n",
    "    res = requests.get(href)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    product = soup.select_one('.product-gallery')\n",
    "    href = product.find('a').get_attribute_list('href')[0]\n",
    "    Javascript = product.find('script')\n",
    "    if Javascript:\n",
    "        pattern = r'var fpdProductsJSON = (\\[\\[\\{.*?\\}\\]\\])'\n",
    "        match = re.search(pattern, Javascript.string)\n",
    "        json_text = match.group(1)\n",
    "        json_parse = json.loads(json_text)\n",
    "        elements = json_parse[0][0][\"elements\"]\n",
    "        images = \"\"\n",
    "        for element in elements:\n",
    "            images = images + \",\" + element[\"source\"]\n",
    "        file_write.write(line.replace(\"\\n\", \"\") + \",\" + href + images + \"\\n\")\n",
    "\n",
    "file_write.close()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "res = requests.get(\"https://hatocase.com/in-op-lung-dien-thoai-xiaomi-12t-pro-theo-yeu-cau/\")\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "product = soup.select_one('.product-gallery')\n",
    "href = product.find('a').get_attribute_list('href')[0]\n",
    "Javascript = product.find('script').string\n",
    "pattern = r'var fpdProductsJSON = (\\[\\[\\{.*?\\}\\]\\])'\n",
    "match = re.search(pattern, Javascript)\n",
    "json_text = match.group(1)\n",
    "json_parse = json.loads(json_text)\n",
    "elements = json_parse[0][0][\"elements\"]\n",
    "for element in elements:\n",
    "    print(element[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m num, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m         group, text, href \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      6\u001b[0m             count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(\"data.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for num, line in enumerate(f, 1):\n",
    "        group, sub_group, text, href = line.split(\",\")\n",
    "        if text == \"\":\n",
    "            count += 1\n",
    "            print(num, line)\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
